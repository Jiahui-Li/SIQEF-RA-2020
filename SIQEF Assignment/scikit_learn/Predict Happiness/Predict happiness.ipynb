{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from scipy import sparse\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入数据\n",
    "train_abbr=pd.read_csv(\"datalab/231702/happiness_train_abbr.csv\",encoding='ISO-8859-1')\n",
    "train=pd.read_csv(\"datalab/231702/happiness_train_complete.csv\",encoding='ISO-8859-1')\n",
    "test_abbr=pd.read_csv(\"datalab/231702/happiness_test_abbr.csv\",encoding='ISO-8859-1')\n",
    "test=pd.read_csv(\"datalab/231702/happiness_test_complete.csv\",encoding='ISO-8859-1')\n",
    "test_sub=pd.read_csv(\"datalab/231702/happiness_submit.csv\",encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#观察数据\n",
    "print(test.shape,test_sub.shape,train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#简单查看数据\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看数据是否缺失\n",
    "train.info(verbose=True,null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看label分布\n",
    "y_train_=train[\"happiness\"]\n",
    "y_train_.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将-8换成3\n",
    "y_train_=y_train_.map(lambda x:3 if x==-8 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#让label从0开始\n",
    "y_train_=y_train_.map(lambda x:x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7a8f763a292c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#train和test连在一起\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#train和test连在一起\n",
    "data = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理时间特征\n",
    "data['survey_time'] = pd.to_datetime(data['survey_time'],format='%Y-%m-%d %H:%M:%S')\n",
    "data[\"weekday\"]=data[\"survey_time\"].dt.weekday\n",
    "data[\"year\"]=data[\"survey_time\"].dt.year\n",
    "data[\"quarter\"]=data[\"survey_time\"].dt.quarter\n",
    "data[\"hour\"]=data[\"survey_time\"].dt.hour\n",
    "data[\"month\"]=data[\"survey_time\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把一天的时间分段\n",
    "def hour_cut(x):\n",
    "    if 0<=x<6:\n",
    "        return 0\n",
    "    elif  6<=x<8:\n",
    "        return 1\n",
    "    elif  8<=x<12:\n",
    "        return 2\n",
    "    elif  12<=x<14:\n",
    "        return 3\n",
    "    elif  14<=x<18:\n",
    "        return 4\n",
    "    elif  18<=x<21:\n",
    "        return 5\n",
    "    elif  21<=x<24:\n",
    "        return 6\n",
    "        \n",
    "data[\"hour_cut\"]=data[\"hour\"].map(hour_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#做问卷时候的年龄\n",
    "data[\"survey_age\"]=data[\"year\"]-data[\"birth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#让label从0开始\n",
    "data[\"happiness\"]=data[\"happiness\"].map(lambda x:x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去掉三个缺失值很多的\n",
    "data=data.drop([\"edu_other\"], axis=1)\n",
    "data=data.drop([\"happiness\"], axis=1)\n",
    "data=data.drop([\"survey_time\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#是否入党\n",
    "data[\"join_party\"]=data[\"join_party\"].map(lambda x:0 if pd.isnull(x)  else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#出生的年代\n",
    "def birth_split(x):\n",
    "    if 1920<=x<=1930:\n",
    "        return 0\n",
    "    elif  1930<x<=1940:\n",
    "        return 1\n",
    "    elif  1940<x<=1950:\n",
    "        return 2\n",
    "    elif  1950<x<=1960:\n",
    "        return 3\n",
    "    elif  1960<x<=1970:\n",
    "        return 4\n",
    "    elif  1970<x<=1980:\n",
    "        return 5\n",
    "    elif  1980<x<=1990:\n",
    "        return 6\n",
    "    elif  1990<x<=2000:\n",
    "        return 7\n",
    "    \n",
    "data[\"birth_s\"]=data[\"birth\"].map(birth_split)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#收入分组\n",
    "def income_cut(x):\n",
    "    if x<0:\n",
    "        return 0\n",
    "    elif  0<=x<1200:\n",
    "        return 1\n",
    "    elif  1200<x<=10000:\n",
    "        return 2\n",
    "    elif  10000<x<24000:\n",
    "        return 3\n",
    "    elif  24000<x<40000:\n",
    "        return 4\n",
    "    elif  40000<=x:\n",
    "        return 5\n",
    " \n",
    "\n",
    "    \n",
    "data[\"income_cut\"]=data[\"income\"].map(income_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#填充数据\n",
    "data[\"edu_status\"]=data[\"edu_status\"].fillna(5)\n",
    "data[\"edu_yr\"]=data[\"edu_yr\"].fillna(-2)\n",
    "data[\"property_other\"]=data[\"property_other\"].map(lambda x:0 if pd.isnull(x)  else 1)\n",
    "data[\"hukou_loc\"]=data[\"hukou_loc\"].fillna(1)\n",
    "data[\"social_neighbor\"]=data[\"social_neighbor\"].fillna(8)\n",
    "data[\"social_friend\"]=data[\"social_friend\"].fillna(8)\n",
    "data[\"work_status\"]=data[\"work_status\"].fillna(0)\n",
    "data[\"work_yr\"]=data[\"work_yr\"].fillna(0)\n",
    "data[\"work_type\"]=data[\"work_type\"].fillna(0)\n",
    "data[\"work_manage\"]=data[\"work_manage\"].fillna(0)\n",
    "data[\"family_income\"]=data[\"family_income\"].fillna(-2)\n",
    "data[\"invest_other\"]=data[\"invest_other\"].map(lambda x:0 if pd.isnull(x)  else 1)\n",
    "data[\"minor_child\"]=data[\"minor_child\"].fillna(0)\n",
    "data[\"marital_1st\"]=data[\"marital_1st\"].fillna(0)\n",
    "data[\"s_birth\"]=data[\"s_birth\"].fillna(0)\n",
    "data[\"marital_now\"]=data[\"marital_now\"].fillna(0)\n",
    "data[\"s_edu\"]=data[\"s_edu\"].fillna(0)\n",
    "data[\"s_political\"]=data[\"s_political\"].fillna(0)\n",
    "data[\"s_hukou\"]=data[\"s_hukou\"].fillna(0)\n",
    "data[\"s_income\"]=data[\"s_income\"].fillna(0)\n",
    "data[\"s_work_exper\"]=data[\"s_work_exper\"].fillna(0)\n",
    "data[\"s_work_status\"]=data[\"s_work_status\"].fillna(0)\n",
    "data[\"s_work_type\"]=data[\"s_work_type\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop([\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = data[:train.shape[0]]\n",
    "X_test_  = data[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'happiness'\n",
    "feature_columns=list(X_test_.columns) \n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train_)\n",
    "y_train = np.array(y_train_)\n",
    "X_test  = np.array(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义评价函数\n",
    "def myFeval(preds, xgbtrain):\n",
    "    label = xgbtrain.get_label()\n",
    "    score = mean_squared_error(label,preds)\n",
    "    return 'myFeval',score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### xgb\n",
    "\n",
    "xgb_params = {\"booster\":'gbtree','eta': 0.005, 'max_depth': 5, 'subsample': 0.7, \n",
    "              'colsample_bytree': 0.8, 'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 8}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_xgb = np.zeros(len(train))\n",
    "predictions_xgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train[val_idx], y_train[val_idx])\n",
    "    \n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=100, params=xgb_params,feval = myFeval)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(X_train[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    \n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, y_train_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### lgb\n",
    "\n",
    "param = {'boosting_type': 'gbdt',\n",
    "         'num_leaves': 20,\n",
    "         'min_data_in_leaf': 20, \n",
    "         'objective':'regression',\n",
    "         'max_depth':6,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 30,\n",
    "         \n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_lgb = np.zeros(len(X_train_))\n",
    "predictions_lgb = np.zeros(len(X_test_))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "   # print(trn_idx)\n",
    "   # print(\".............x_train.........\")\n",
    "   # print(X_train[trn_idx])\n",
    "  #  print(\".............y_train.........\")\n",
    "  #  print(y_train[trn_idx])\n",
    "    trn_data = lgb.Dataset(X_train[trn_idx], y_train[trn_idx])\n",
    "    \n",
    "    val_data = lgb.Dataset(X_train[val_idx], y_train[val_idx])\n",
    "    \n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=200, early_stopping_rounds = 100)\n",
    "    oof_lgb[val_idx] = clf.predict(X_train[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, y_train_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#安装catboost的包\n",
    "!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostRegressor\n",
    "# cat_features=[0,2,3,10,11,13,15,16,17,18,19]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_train_, y_train_, test_size=0.3, random_state=2019)\n",
    "# train_pool = Pool(X_train_s, y_train_s,cat_features=[0,2,3,10,11,13,15,16,17,18,19])\n",
    "# val_pool = Pool(X_test_s, y_test_s,cat_features=[0,2,3,10,11,13,15,16,17,18,19])\n",
    "# test_pool = Pool(X_test_ ,cat_features=[0,2,3,10,11,13,15,16,17,18,19]) \n",
    "\n",
    "\n",
    "kfolder = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_cb = np.zeros(len(X_train_))\n",
    "predictions_cb = np.zeros(len(X_test_))\n",
    "kfold = kfolder.split(X_train_, y_train_)\n",
    "fold_=0\n",
    "#X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_train, y_train, test_size=0.3, random_state=2019)\n",
    "for train_index, vali_index in kfold:\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    fold_=fold_+1\n",
    "    k_x_train = X_train[train_index]\n",
    "    k_y_train = y_train[train_index]\n",
    "    k_x_vali = X_train[vali_index]\n",
    "    k_y_vali = y_train[vali_index]\n",
    "    cb_params = {\n",
    "         'n_estimators': 100000,\n",
    "         'loss_function': 'RMSE',\n",
    "         'eval_metric':'RMSE',\n",
    "         'learning_rate': 0.05,\n",
    "         'depth': 5,\n",
    "         'use_best_model': True,\n",
    "         'subsample': 0.6,\n",
    "         'bootstrap_type': 'Bernoulli',\n",
    "         'reg_lambda': 3\n",
    "    }\n",
    "    model_cb = CatBoostRegressor(**cb_params)\n",
    "    #train the model\n",
    "    model_cb.fit(k_x_train, k_y_train,eval_set=[(k_x_vali, k_y_vali)],verbose=100,early_stopping_rounds=50)\n",
    "    oof_cb[vali_index] = model_cb.predict(k_x_vali, ntree_end=model_cb.best_iteration_)\n",
    "    predictions_cb += model_cb.predict(X_test_, ntree_end=model_cb.best_iteration_) / kfolder.n_splits\n",
    "\n",
    "\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_cb, y_train_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "# 将lgb和xgb和ctb的结果进行stacking\n",
    "train_stack = np.vstack([oof_lgb,oof_xgb,oof_cb]).transpose()\n",
    "test_stack = np.vstack([predictions_lgb, predictions_xgb,predictions_cb]).transpose()\n",
    "\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=2018)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack,y_train)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], y_train[trn_idx]\n",
    "    val_data, val_y = train_stack[val_idx], y_train[val_idx]\n",
    "    \n",
    "    clf_3 = linear_model.BayesianRidge()\n",
    "    #clf_3 =linear_model.Ridge()\n",
    "    clf_3.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack[val_idx] = clf_3.predict(val_data)\n",
    "    predictions += clf_3.predict(test_stack) / 10\n",
    "    \n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_stack, y_train_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=list(predictions)\n",
    "result=list(map(lambda x: x + 1, result))\n",
    "test_sub[\"happiness\"]=result\n",
    "test_sub.to_csv(\"submit_20190515.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
